{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.examples.tutorials.mnist  import  input_data\n",
    "#mnist = input_data.read_data_sets('../99.MNIST_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# real_dim : 本物データの次元\n",
    "# z_dim : フェイクデータの次元\n",
    "def model_imputs(real_dim, z_dim):\n",
    "    inputs_real = tf.placeholder(tf.float32, (None, real_dim), name='input_real')\n",
    "    inputs_z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n",
    "    \n",
    "    return inputs_real, inputs_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reuse : False 呼び出すたびに、関数のなかの前回実行時の値を保持するかどうかを指定\n",
    "def generator(z, out_dim, n_units=128, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        h1 = tf.layers.dense(z, n_units, activation=None)\n",
    "        h1 = tf.maximum(alpha * h1, h1) # Leaky ReLU\n",
    "        \n",
    "        logits = tf.layers.dense(h1, out_dim, activation=None)\n",
    "        out = tf.tanh(logits)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### discriminator関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reuse : False 呼び出すたびに、関数のなかの前回実行時の値を保持するかどうかを指定\n",
    "def discriminator(z, n_units=128, reuse=False, alpha=0.01):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse): # discriminatorと名前をつけて呼ばれた場合は前回の演算の値を保持する\n",
    "        h1 = tf.layers.dense(z, n_units, activation=None)\n",
    "        h1 = tf.maximum(alpha * h1, h1) # Leaky ReLU\n",
    "        \n",
    "        logits = tf.layers.dense(h1, 1, activation=None)\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        return out, logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# パイパーパラメータの初期化\n",
    "input_size = 784\n",
    "z_size = 100\n",
    "g_hidden_size = 128\n",
    "d_hidden_size = 128\n",
    "alpha = 0.01\n",
    "smooth = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input_real, input_z = model_imputs(input_size, z_size)\n",
    "\n",
    "g_model = generator(input_z, input_size, n_units=g_hidden_size, alpha=alpha)\n",
    "\n",
    "d_model_real, d_logits_real = discriminator(input_real, n_units=d_hidden_size, alpha=alpha)\n",
    "d_model_fake, d_logits_fake = discriminator(g_model, reuse=True, n_units=d_hidden_size, alpha=alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数を定義（D/G）\n",
    "# 正解から離れていると値が大きく発散する\n",
    "d_loss_real = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n",
    "                                                                      labels=tf.ones_like(d_logits_real) *(1-smooth)))\n",
    "d_loss_fake = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                      labels=tf.zeros_like(d_logits_real)))\n",
    "\n",
    "d_loss = d_loss_real  + d_loss_fake\n",
    "\n",
    "# ランダムに生成された画像が本物として認識された誤差\n",
    "g_loss =  tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n",
    "                                                                labels=tf.ones_like(d_logits_fake)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法を定義\n",
    "learning_rate = 0.002\n",
    "\n",
    "t_vars = tf.trainable_variables() # weight / bias を取り出す\n",
    "g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "\n",
    "d_train_optimaize = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "g_train_optimaize = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
